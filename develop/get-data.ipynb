{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook retrieves several data points from reddit and saves it to csv files\n",
    "\n",
    "# Imports\n",
    "import praw\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a subreddit to retrieve data from\n",
    "subreddit = 'christianity'\n",
    "\n",
    "# Choose the number of hot posts to retrieve from the subreddit\n",
    "num_posts_to_retrieve = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login and create Reddit instance\n",
    "myClientIDvar = '7H-wkx3wmj96hJazvWQb-A'\n",
    "myClientSecret = 'kKTtoMJA0gYXEr9d0ohMp-niRM0yhw'\n",
    "myRedditUserName = 'Legitimate_Thing5210'\n",
    "reddit = praw.Reddit(client_id=myClientIDvar, client_secret=myClientSecret, user_agent=myRedditUserName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Returns a generator that generates the n hottest posts from a subreddit\n",
    "\n",
    "Ex: Get the hottest 30 posts from r/christianity:\n",
    "  generator = getHotPosts(30, 'christianity')\n",
    "\"\"\"\n",
    "\n",
    "def getHotPosts(numPosts, subreddit):\n",
    "  return reddit.subreddit(subreddit).hot(limit=numPosts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "Return a Dataframe of posts and information from a generator\n",
    "\n",
    "Ex: Return a dataframe with info about the 30 hottest posts on r/christianity\n",
    "  generator = getHotPosts(30, 'christianity')\n",
    "  dfPosts = getPostsDf(generator, 10)\n",
    "  dfPosts = dfPosts.append(getPostsDf(generator, 10))\n",
    "  dfPosts = dfPosts.append(getPostsDf(generator, 10))\n",
    "\"\"\"\n",
    "\n",
    "def getHotPostsDf(postings_generator, n_postings):\n",
    "  post_info_list = []\n",
    "\n",
    "  for i in range(n_postings):\n",
    "    try:\n",
    "      submission = next(postings_generator)\n",
    "    except:\n",
    "      print(\"No more posts to generate\")\n",
    "      break\n",
    "\n",
    "    post_info_list.append({\n",
    "      'ID': submission.id,\n",
    "      'Sub': submission.subreddit,\n",
    "      'Title': submission.title,\n",
    "      'URL': submission.permalink,\n",
    "      'Time': datetime.datetime.fromtimestamp(submission.created_utc),\n",
    "      'Author': str(submission.author),\n",
    "      'Body': submission.selftext,\n",
    "      'IsSelfPost': bool(submission.is_self)\n",
    "    })\n",
    "\n",
    "  return pd.DataFrame(post_info_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Return a Dataframe with information about the authors of posts from a Dataframe of posts\n",
    "\"\"\"\n",
    "def getAuthorInfoDF(dfPosts):\n",
    "\n",
    "  author_list = []\n",
    "\n",
    "  for indexAuthor, id in enumerate(dfPosts['ID']):\n",
    "    # Get Entry Information\n",
    "    thisSubmission = reddit.submission(id=id)\n",
    "    thisAuthor = thisSubmission.author\n",
    "\n",
    "    # Get Author Information\n",
    "\n",
    "    # Verifies that author exists and has not been suspended (as suspended accounts do not have most attributes)\n",
    "    if (thisSubmission.author is None) or not hasattr(thisAuthor, 'created_utc'):\n",
    "      continue\n",
    "\n",
    "    TempDictAuthor = {\n",
    "      'userName': thisAuthor.name,\n",
    "      'numTrophies': len(thisAuthor.trophies()),\n",
    "      'accountAge': thisAuthor.created_utc,\n",
    "      'totalKarma': thisAuthor.total_karma,\n",
    "      'linkKarma': thisAuthor.link_karma,\n",
    "      'commentKarma': thisAuthor.comment_karma,\n",
    "      'awarderKarma': thisAuthor.awarder_karma,\n",
    "      'awardeeKarma': thisAuthor.awardee_karma,\n",
    "      'isMod': thisAuthor.is_mod,\n",
    "    }\n",
    "    TempDictAuthor['numComments'] = sum(1 for _ in thisAuthor.comments.top(time_filter=\"month\"))\n",
    "\n",
    "    author_list.append(TempDictAuthor)\n",
    "\n",
    "    print('Retrieved data for ' + str(indexAuthor + 1) + ' authors')\n",
    "\n",
    "  dfAuthors = pd.DataFrame(author_list)\n",
    "  dfAuthors['isMod'] = dfAuthors['isMod'].astype('bool')\n",
    "  \n",
    "  return dfAuthors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Return a Dataframe with information about the posts that authors \n",
    "\"\"\"\n",
    "def getPostsByAuthors(dfAuthors):\n",
    "  usernames = dfAuthors[\"userName\"].drop_duplicates()\n",
    "  posts_lists = []\n",
    "\n",
    "  for username in usernames:\n",
    "    thisAuthor = reddit.redditor(name=username)\n",
    "    for thisAuthorPost in thisAuthor.submissions.top(time_filter=\"month\"):\n",
    "      posts_lists.append({\n",
    "        'ID': thisAuthorPost.id,\n",
    "        'Author': str(thisAuthor),\n",
    "        'Sub': thisAuthorPost.subreddit,\n",
    "        'Title': thisAuthorPost.title,\n",
    "        'Body': thisAuthorPost.selftext,\n",
    "        'Upvotes': thisAuthorPost.ups,\n",
    "        'Upvote Ratio': thisAuthorPost.upvote_ratio,\n",
    "        'Awards': thisAuthorPost.total_awards_received,\n",
    "        'URL': thisAuthorPost.permalink,\n",
    "        'Time': datetime.datetime.fromtimestamp(thisAuthorPost.created_utc),\n",
    "        'IsSelfPost': bool(thisAuthorPost.is_self)\n",
    "      })\n",
    "  return pd.DataFrame(posts_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Return a Dataframe with information about the comments from posts\n",
    "Retrieves a maximum of 20 comments per post\n",
    "\"\"\"\n",
    "def getCommentsByPosts(dfPosts):\n",
    "  comments_list = []\n",
    "\n",
    "  max_comments_per_post = 20\n",
    "\n",
    "  for postID in dfPosts[\"ID\"]:\n",
    "\n",
    "    thisSubmission = reddit.submission(id=postID)\n",
    "    thisSubmission.comments.replace_more(limit=0)\n",
    "\n",
    "    for num_comment, tempComment in enumerate(thisSubmission.comments.list()):\n",
    "      if num_comment + 1 > max_comments_per_post:\n",
    "        break\n",
    "\n",
    "      if not hasattr(tempComment,'is_submitter'):\n",
    "        continue\n",
    "      \n",
    "      comments_list.append({\n",
    "        'ID': tempComment.id,\n",
    "        'Author': tempComment.author,\n",
    "        'Post ID': tempComment.submission,\n",
    "        'Body': str(tempComment.body),\n",
    "      })\n",
    "  \n",
    "  return pd.DataFrame(comments_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Converts a Dataframe to CSV File. If './results/target_csv_file' doesn't exist, creates the file.\n",
    "Otherwise appends the dataframe to the existing file\n",
    "'''\n",
    "\n",
    "def DFtoCSV(df, target_csv_file='output.csv'):\n",
    "  if not os.path.exists('./results'):\n",
    "    os.makedirs('./results')\n",
    "\n",
    "  path = './results/' + target_csv_file\n",
    "  if os.path.exists(path):\n",
    "    df.to_csv(path, mode='a', index=False, header=False)\n",
    "  else:\n",
    "    df.to_csv(path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Reads data from a CSV file found in the 'results' folder and returns a Dataframe\n",
    "'''\n",
    "def CSVtoDF(csv_file):\n",
    "  return pd.read_csv('./results/' + csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_generator = getHotPosts(num_posts_to_retrieve, subreddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPosts = getHotPostsDf(post_generator, 30)\n",
    "DFtoCSV(dfPosts, subreddit + '_hot_posts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPosts = CSVtoDF(subreddit + '_hot_posts.csv')\n",
    "DFtoCSV(getAuthorInfoDF(dfPosts), subreddit + '_authors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAuthors = CSVtoDF(subreddit + '_authors.csv')\n",
    "DFtoCSV(getPostsByAuthors(dfAuthors), subreddit + '_posts_by_authors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPostsByAuthors = CSVtoDF(subreddit + '_posts_by_authors.csv')\n",
    "DFtoCSV(getCommentsByPosts(dfPostsByAuthors), subreddit + '_comments.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('friends')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd509f55d2ff13b9dce411278cca8822fba0ca9d097902de44aa53238c8ee558"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
